{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a7b6c8-2e7e-428a-905e-b347226525fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b617e8d-0c13-4b26-932d-c966111e99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, document_handler, image_handler):\n",
    "        self.document_handler = document_handler\n",
    "        self.image_handler = image_handler\n",
    "        self.llm = ChatOllama(model=Config.GEMMA_MODEL, temperature=Config.TEMPERATURE)\n",
    "        self.llm_image = ChatOllama(model=Config.LLAVA_MODEL, temperature=Config.TEMPERATURE)\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            output_key=\"answer\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=Config.PROMPT_TEMPLATE,\n",
    "            input_variables=[\"chat_history\", \"context\", \"question\"]\n",
    "        )\n",
    "        self.qa_chain = self.initialize_qa_chain()\n",
    "\n",
    "    def initialize_qa_chain(self, custom_db=None):\n",
    "        db = custom_db if custom_db else self.document_handler.initialize_db()\n",
    "        return ConversationalRetrievalChain.from_llm(\n",
    "            self.llm,\n",
    "            db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "            return_source_documents=True,\n",
    "            verbose=True,\n",
    "            combine_docs_chain_kwargs={\"prompt\": self.prompt},\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def chat(self, message, history, image=None):\n",
    "        try:\n",
    "            chat_history = [(human, ai) for human, ai in history]\n",
    "            answer = \"\"\n",
    "            \n",
    "            if image is not None:\n",
    "                processed_image = self.image_handler.process_image(image)\n",
    "                if processed_image:\n",
    "                    messages = [\n",
    "                        HumanMessage(\n",
    "                            content=[\n",
    "                                {\"type\": \"text\", \"text\": message},\n",
    "                                {\"type\": \"image_url\", \"image_url\": processed_image}\n",
    "                            ]\n",
    "                        )\n",
    "                    ]\n",
    "                    \n",
    "                    try:\n",
    "                        response = self.llm_image.invoke(messages)\n",
    "                        image_answer = response.content\n",
    "                        answer = f\"이미지 분석 결과: {image_answer}\"\n",
    "                    except Exception as img_error:\n",
    "                        print(f\"이미지 분석 중 오류 발생: {str(img_error)}\")\n",
    "                        answer = f\"이미지 분석 중 오류가 발생했습니다: {str(img_error)}\"\n",
    "            \n",
    "            if not image:\n",
    "                text_response = self.qa_chain({\"question\": message, \"chat_history\": chat_history})\n",
    "                text_answer = text_response['answer']\n",
    "                \n",
    "                if 'source_documents' in text_response:\n",
    "                    sources = set([os.path.basename(doc.metadata.get('source', 'Unknown')) \n",
    "                                 for doc in text_response['source_documents']])\n",
    "                    source_info = f\"\\n\\n참고 파일: {', '.join(sources)}\" if sources else \"\"\n",
    "                    text_answer += source_info\n",
    "                \n",
    "                answer = text_answer if not answer else f\"{answer}\\n\\n텍스트 응답: {text_answer}\"\n",
    "                \n",
    "            chat_history.append((message, answer))\n",
    "            return \"\", chat_history, None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"채팅 함수 실행 중 오류 발생: {str(e)}\")\n",
    "            error_message = f\"죄송합니다. 오류가 발생했습니다: {str(e)}\"\n",
    "            chat_history.append((message, error_message))\n",
    "            return \"\", chat_history, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb34ad-172c-4748-bea1-f8048b16f958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

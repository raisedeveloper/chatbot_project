{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26c88b7-52c7-445a-8407-ee39fe958604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d4e395-4cf9-4aee-a72a-77a18dabd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Config.setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed7c6c0-a295-46f5-a9d0-c9b599bbea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalLanguageGenerator:\n",
    "    \"\"\"쿼리 결과를 자연어로 설명하는 클래스\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\"\n",
    "        다음 데이터베이스 쿼리 결과를 자연스러운 한국어로 설명해주세요:\n",
    "        컬럼: {columns}\n",
    "        결과: {results}\n",
    "        \n",
    "        규칙:\n",
    "        1. 친근하고 대화체로 설명해주세요\n",
    "        2. 중요한 정보를 강조해주세요\n",
    "        3. 결과의 의미를 해석해서 설명해주세요\n",
    "        4. 필요한 경우 추가 컨텍스트를 제공해주세요\n",
    "        \"\"\"\n",
    "        self.llm = Ollama(model=\"gemma2\", temperature=0.3)\n",
    "        self.chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=ChatPromptTemplate.from_template(self.template)\n",
    "        )\n",
    "\n",
    "    def generate_summary(self, columns: Tuple[str], rows: List[Tuple]) -> str:\n",
    "        \"\"\"쿼리 결과를 자연어로 설명합니다.\"\"\"\n",
    "        if not rows:\n",
    "            return \"검색된 결과가 없습니다. 다른 검색어로 시도해보시겠어요?\"\n",
    "        \n",
    "        try:\n",
    "            summary = self.chain.run(\n",
    "                columns=\", \".join(columns),\n",
    "                results=str(rows)\n",
    "            )\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"자연어 생성 중 오류 발생: {e}\")\n",
    "            return self._generate_fallback_summary(columns, rows)\n",
    "\n",
    "    def _generate_fallback_summary(self, columns: Tuple[str], rows: List[Tuple]) -> str:\n",
    "        \"\"\"오류 발생 시 기본적인 설명을 생성합니다.\"\"\"\n",
    "        summary = []\n",
    "        for row in rows:\n",
    "            description = \"검색 결과: \"\n",
    "            for col, val in zip(columns, row):\n",
    "                formatted_val = str(val).strip('()[]{}\\\\\\'\\\"')\n",
    "                description += f\"{col}는 {formatted_val}, \"\n",
    "            summary.append(description.rstrip(\", \") + \"입니다.\")\n",
    "        return \"\\n\".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34553f56-1279-4e13-8d12-60418a3a8ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
